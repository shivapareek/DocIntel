# DocIntel

> AIâ€‘powered document intelligence platform built with **FastAPI**, **React + Tailwind CSS**, and free/openâ€‘source largeâ€‘language models. Upload PDFs, get smart summaries, ask questions in Hinglish/English, and practise with autoâ€‘generated quizzes â€“ sab kuch ek hi jagah! ğŸ”¥


---

## Table of Contents

1. [Features](#features)  
2. [Architecture](#architecture)  
3. [QuickÂ Start](#quick-start)  
4. [DetailedÂ Setup](#detailed-setup)  
   - [Backend](#backend-setup)  
   - [Frontend](#frontend-setup)  
5. [FolderÂ Structure](#folder-structure)  
6. [Roadmap](#roadmap)  
7. [Contributing](#contributing)  
8. [License](#license)

---

## Features

| â­ | Feature | Description |
| :-- | :-- | :-- |
| ğŸ“„ | **PDF UploadÂ & Parsing** | Dragâ€‘andâ€‘drop PDFs; parsing via **PyMuPDF/pdfplumber** with automatic metadata extraction |
| ğŸ” | **RAGâ€‘based Q&A** | Hybrid keyword + vector search powered by **LangChain/LlamaIndex** and local **Mistralâ€‘7B** (no paid APIs) |
| ğŸ“ | **Smooth Summaries** | Oneâ€‘click generation of paragraphâ€‘style summaries with highlighted key terms (per user preference) |
| â” | **ChallengeÂ Mode** | Dynamic MCQs with correctness, score, feedback, justification & reference text (ideal for exam prep) |
| ğŸ‡®ğŸ‡³ | **Hindiâ€‘friendly** | Responses can switch between English or Hinglish as needed |
| ğŸ¨ | **ModernÂ UI** | Responsive ReactÂ +Â Tailwind, darkâ€‘mode toggle, soft shadows, smooth animations |
| âš¡ | **Fast & Light** | No heavyweight DB; inâ€‘memory doc store for quick prototyping, pluggable with Postgres/Chroma later |

---

## Architecture

```mermaid
flowchart LR
    subgraph Client
        A[ReactÂ App]
    end
    subgraph Server
        B[FastAPIÂ Gateway]
        C[RAGService](DocumentÂ Memory)
        D[LLMÂ Runtime](MistralÂ 7B â€“Â gguf)
    end
    A -- RESTÂ +Â WebSocket --> B
    B -- DocumentÂ chunks --> C
    C -- PromptÂ +Â Context --> D
    D -- JSONÂ response --> C
    C -- AnswerÂ /Â QuizÂ JSON --> B
    B -- JSON --> A
```

> **FlowÂ Explanation:**  
> 1. **Client** uploads a PDF â†’ FastAPI streams file to the server.  
> 2. **RAGService** splits & embeds chunks; stores metadata in memory.  
> 3. For each query/quiz request, contextual prompt is built & sent to **LLM Runtime**.  
> 4. Generated answer/MCQs return to the client for display.

---

## QuickÂ Start

```bash
# 1. Clone ğŸ› ï¸
git clone https://github.com/shivapareek/DocIntel.git && cd DocIntel

# 2. Fire up everything with Docker ğŸ³
docker compose up --build

# 3. Open http://localhost:5173  (frontend)
#    Backend runs on http://localhost:8000
```

> **Note:** Default compose pulls a preâ€‘quantised Mistralâ€‘7Bâ€‘Instruct model (â‰ˆ4â€¯GB). First run may take a while.

---

## DetailedÂ Setup

### BackendÂ Setup

```bash
cd backend
python -m venv .venv && source .venv/bin/activate
pip install -r requirements.txt

# Environment vars
cp .env.example .env  # edit as needed

# Run server
uvicorn main:app --reload --host 0.0.0.0 --port 8000
```


### FrontendÂ Setup

```bash
cd frontend
npm run dev
```
---

## FolderÂ Structure

```text
DocIntel/
â”œâ”€ backend/
â”‚  â”œâ”€ app/
â”‚  â”‚  â”œâ”€ main.py
â”‚  â”‚  â”œâ”€ services/
â”‚  â”‚  â”‚   â””â”€ rag.py
â”‚  â”‚  â”œâ”€ auth/
â”‚  â”‚  â”‚   â””â”€ jwt.py
â”‚  â”‚  â””â”€ routes/
â”‚  â””â”€ requirements.txt
â”œâ”€ frontend/
â”‚  â”œâ”€ src/
â”‚  â”‚  â”œâ”€ components/
â”‚  â”‚  â”œâ”€ pages/
â”‚  â”‚  â””â”€ context/
â”‚  â”œâ”€ Dockerfile
â”‚  â””â”€ vite.config.ts
â”œâ”€ docs/             # design docs & images
â””â”€ docker-compose.yml
```

---

## Contributing

PullÂ requests welcome! **Fork â†’ Branch â†’ PR**. Please open an issue for major changes.

```bash
git checkout -b feat/awesome-feature
# Commit & push, then open PR ğŸ™Œ
```

---

> *Built with â¤ï¸ by ShivaÂ Pareek.*
